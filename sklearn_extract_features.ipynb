{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sklearn_extract_features.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "aQTh9cFI-nBR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# sklearn.feature_extraction"
      ]
    },
    {
      "metadata": {
        "id": "ApAXlk49_trQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## DictVectorizer\n",
        "Implement one-of-K or one-hot coding for categorical features"
      ]
    },
    {
      "metadata": {
        "id": "N4Qvi01Z-gTk",
        "colab_type": "code",
        "outputId": "75c80628-2abb-4942-8e24-d4d568e69f6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "org_data = [{'name': 'Ann', 'age': 30},\n",
        "           {'name': 'Dave', 'age': 32},\n",
        "           {'name': 'Kavin', 'age': 31}]\n",
        "\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "vec = DictVectorizer()\n",
        "\n",
        "print('New data\\n', vec.fit_transform(org_data).toarray())\n",
        "\n",
        "print('\\nFeatures\\n', vec.get_feature_names())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New data\n",
            " [[30.  1.  0.  0.]\n",
            " [32.  0.  1.  0.]\n",
            " [31.  0.  0.  1.]]\n",
            "\n",
            "Features\n",
            " ['age', 'name=Ann', 'name=Dave', 'name=Kavin']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GyjuXBxVElNC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Text feature extraction"
      ]
    },
    {
      "metadata": {
        "id": "q_MmIV9LRd_7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### CountVectorizer"
      ]
    },
    {
      "metadata": {
        "id": "1VuzPFT4jnje",
        "colab_type": "code",
        "outputId": "5e58724a-dae8-4fe8-9366-87092bca554b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corprus = ['I see a cat.',\n",
        "           'It is yellow and brown.',\n",
        "           'His house is cozy and beautiful.'\n",
        "          ]\n",
        "\n",
        "vec = CountVectorizer()\n",
        "\n",
        "X = vec.fit_transform(corprus)\n",
        "\n",
        "# print(X)\n",
        "\n",
        "print(vec.get_feature_names())\n",
        "\n",
        "print(X.toarray())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'beautiful', 'brown', 'cat', 'cozy', 'his', 'house', 'is', 'it', 'see', 'yellow']\n",
            "[[0 0 0 1 0 0 0 0 0 1 0]\n",
            " [1 0 1 0 0 0 0 1 1 0 1]\n",
            " [1 1 0 0 1 1 1 1 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z1z0WbgRmtkP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TfidfVectorizer"
      ]
    },
    {
      "metadata": {
        "id": "19OY0XaTmvoJ",
        "colab_type": "code",
        "outputId": "49632dc6-f902-482a-bdfb-25a661b11781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "corprus = ['I see a cat.',\n",
        "           'It is yellow and brown.',\n",
        "           'His house is cozy and beautiful.'\n",
        "          ]\n",
        "\n",
        "vec = TfidfVectorizer()\n",
        "\n",
        "X = vec.fit_transform(corprus)\n",
        "\n",
        "# print(X)\n",
        "\n",
        "print(vec.get_feature_names())\n",
        "\n",
        "print(X.toarray())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'beautiful', 'brown', 'cat', 'cozy', 'his', 'house', 'is', 'it', 'see', 'yellow']\n",
            "[[0.         0.         0.         0.70710678 0.         0.\n",
            "  0.         0.         0.         0.70710678 0.        ]\n",
            " [0.37302199 0.         0.49047908 0.         0.         0.\n",
            "  0.         0.37302199 0.49047908 0.         0.49047908]\n",
            " [0.3349067  0.44036207 0.         0.         0.44036207 0.44036207\n",
            "  0.44036207 0.3349067  0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rHkZeQasblEp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# sklearn.preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "HqFlkfyAH-35",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Standardization\n",
        "Gaussian with zero mean and unit variance"
      ]
    },
    {
      "metadata": {
        "id": "qP3JNPD5J_KS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### scale\n",
        "Standardize a dataset along any axis.\n",
        "\n",
        "scale()\n",
        "\n",
        "minmax_scale()\n",
        "\n",
        "maxabs_scale()\n",
        "\n",
        "robust_scale()\n"
      ]
    },
    {
      "metadata": {
        "id": "MFgVIhfJ1Dhi",
        "colab_type": "code",
        "outputId": "da56991f-4cbe-45a8-b437-49a2175ba6f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "X_train = np.array([[ 1., -1.,  2.],\n",
        "                    [ 2.,  0.,  0.],\n",
        "                    [ 0.,  1., -1.]])\n",
        "X_scaled = preprocessing.scale(X_train)\n",
        "\n",
        "print(X_train.mean(axis=0))\n",
        "\n",
        "print(X_train.std(axis=0))\n",
        "\n",
        "print(X_scaled.mean(axis=0))\n",
        "\n",
        "print(X_scaled.std(axis=0))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.         0.         0.33333333]\n",
            "[0.81649658 0.81649658 1.24721913]\n",
            "[0. 0. 0.]\n",
            "[1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "REG5yZkDKBCC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### StandardScaler\n",
        "Standardize features by removing the mean and scaling to unit variance.\n",
        "\n",
        "Note: It is possible to disable either centering or scaling by either passing with_mean=False or with_std=False"
      ]
    },
    {
      "metadata": {
        "id": "l3ctiYkpKH8D",
        "colab_type": "code",
        "outputId": "6a0cec18-d346-48af-a7b0-0e876b442c9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "X_train = np.random.rand(12).reshape(3,4)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "print('Contructor: ', scaler)\n",
        "\n",
        "scaler.fit(X_train)\n",
        "\n",
        "print('\\n Mean: \\n', scaler.mean_)\n",
        "print('\\n Scale: \\n', scaler.scale_)\n",
        "\n",
        "print('\\n Scaler.transform:\\n', scaler.transform(X_train))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Contructor:  StandardScaler(copy=True, with_mean=True, with_std=True)\n",
            "\n",
            " Mean: \n",
            " [0.47822047 0.50407115 0.67461575 0.42355057]\n",
            "\n",
            " Scale: \n",
            " [0.29220594 0.25149107 0.19829195 0.38773293]\n",
            "\n",
            " Scaler.transform:\n",
            " [[ 1.34269301 -1.17613446 -1.24955992  1.36467655]\n",
            " [-1.0559003  -0.09202895  0.05123834 -1.00365343]\n",
            " [-0.28679271  1.2681634   1.19832159 -0.36102312]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UZS4-DRtNwpZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### MinMaxScaler\n",
        "Transform features by scaling each feature to a given range, [0, 1] by default"
      ]
    },
    {
      "metadata": {
        "id": "7HNwvcU9N1u_",
        "colab_type": "code",
        "outputId": "8cf24bb2-23f4-483b-90db-d601ec9c9a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "X_train = np.random.rand(12).reshape(3,4)\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "print('\\n Constructor: ', scaler)\n",
        "\n",
        "scaler.fit(X_train)\n",
        "\n",
        "print('\\n Transform: \\n', scaler.transform(X_train))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Constructor:  MinMaxScaler(copy=True, feature_range=(0, 1))\n",
            "\n",
            " Transform: \n",
            " [[0.         1.         0.         0.88879126]\n",
            " [1.         0.         1.         0.        ]\n",
            " [0.60075368 0.30165653 0.44165936 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C3CfUbePPSOE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### MaxAbsScaler\n",
        "Transform each feature by its maximum absolute value. Outputs are in the fixed range [-1, 1]"
      ]
    },
    {
      "metadata": {
        "id": "2EZ3ojYfPmLl",
        "colab_type": "code",
        "outputId": "b0d68ad9-1472-4747-b351-82ecc31f7a81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "import numpy as np\n",
        "\n",
        "X_train = np.random.rand(12).reshape(3, 4)\n",
        "\n",
        "scaler = MaxAbsScaler()\n",
        "\n",
        "print('\\n Constructor: ', scaler)\n",
        "\n",
        "scaler.fit(X_train)\n",
        "\n",
        "print('\\n Transform: \\n', scaler.transform(X_train))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Constructor:  MaxAbsScaler(copy=True)\n",
            "\n",
            " Transform: \n",
            " [[1.         0.35022627 1.         0.02544788]\n",
            " [0.43130671 1.         0.99441364 1.        ]\n",
            " [0.62889325 0.32092059 0.24544743 0.56194918]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RmZwiL6ATvRD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### RobustScaler\n",
        "Transform features using statistics that are robust to outliers."
      ]
    },
    {
      "metadata": {
        "id": "fTMWLVLKT4YN",
        "colab_type": "code",
        "outputId": "47d24a19-80ac-453d-fc38-19642a18632b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "X_train = [[ 1., -2.,  2.],\n",
        "     [ -2.,  1.,  3.],\n",
        "     [ 4.,  1., -2.]]\n",
        "scaler = RobustScaler()\n",
        "\n",
        "print('\\n Constructor:\\n', scaler)\n",
        "\n",
        "scaler.fit(X_train)\n",
        "\n",
        "print('\\n Transform: \\n', scaler.transform(X_train))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Constructor:\n",
            " RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
            "       with_scaling=True)\n",
            "\n",
            " Transform: \n",
            " [[ 0.  -2.   0. ]\n",
            " [-1.   0.   0.4]\n",
            " [ 1.   0.  -1.6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rz2n_IjcS_CY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Note\n",
        "- MinMaxScaler is recommended for sparse data.\n",
        "\n",
        "- scale() and StandardScaler can support well sparse data as long as *with_mean=False*\n",
        "\n",
        "- If data contrains many outliers, robust_scale() and RobustScaler are recommended."
      ]
    },
    {
      "metadata": {
        "id": "QoGdeKwUcHnP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Non-linear transformation"
      ]
    },
    {
      "metadata": {
        "id": "htrD1eHH7c3y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### QuantileTransformer\n",
        "- Map to a Uniform distribution.\n",
        "- Spread out the most frequent values\n",
        "- Reduce the impact of outliers"
      ]
    },
    {
      "metadata": {
        "id": "CmsB953scH5F",
        "colab_type": "code",
        "outputId": "930ff86e-4f1f-446c-8239-f8da28fce5bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "quantile_transformer = QuantileTransformer(random_state=0)\n",
        "\n",
        "X_t = quantile_transformer.fit_transform(X)\n",
        "\n",
        "print(X_t[:5])\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.24174174 0.85585586 0.11411411 0.12762763]\n",
            " [0.12412412 0.46646647 0.11411411 0.12762763]\n",
            " [0.06406406 0.67117117 0.04704705 0.12762763]\n",
            " [0.04354354 0.59059059 0.2012012  0.12762763]\n",
            " [0.17767768 0.88938939 0.11411411 0.12762763]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1SCEWINSAAkK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### PowerTransformer\n",
        "- Make data more Gausian-like\n",
        "\n",
        "- Be useful for modeling issues related to heteroscedasticity (non-constant variance)\n",
        "\n",
        "- Algorithms:\n",
        "\n",
        "  Box-Cox can only be applied to strictly positive data.\n",
        "\n",
        "  Yeo-Johnson supports both positive or negative data (Default)"
      ]
    },
    {
      "metadata": {
        "id": "WCeJ-LLoCH25",
        "colab_type": "code",
        "outputId": "b187c841-69df-4b3e-acbf-c013acca5c8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PowerTransformer\n",
        "import numpy as np\n",
        "\n",
        "X = np.random.rand(12).reshape(3,4)\n",
        "\n",
        "print('\\n Orginial data:\\n', X)\n",
        "\n",
        "power_transformer = PowerTransformer()\n",
        "\n",
        "X_t = power_transformer.fit_transform(X)\n",
        "\n",
        "print('\\n Transform:\\n', X_t)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Orginial data:\n",
            " [[0.24230513 0.68013085 0.3199994  0.45674358]\n",
            " [0.02086126 0.86925737 0.67650581 0.74300248]\n",
            " [0.27964695 0.79594602 0.24944486 0.20798391]]\n",
            "\n",
            " Transform:\n",
            " [[ 0.38510158 -1.26549469 -0.28691561  0.00699068]\n",
            " [-1.37101275  1.17945787  1.34273241  1.22123457]\n",
            " [ 0.98591117  0.08603682 -1.0558168  -1.22822525]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PDCOi5yxEKO_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Normalization\n",
        "The process of scaling individual samples to have unit norm.\n",
        "\n",
        "normalize()\n",
        "\n",
        "Normalizer"
      ]
    },
    {
      "metadata": {
        "id": "WisNOllgENOe",
        "colab_type": "code",
        "outputId": "431ff56d-008c-4b53-ad17-17c2949ea6e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize, Normalizer\n",
        "\n",
        "X_train = [[ 1., -2.,  2.],\n",
        "     [ -2.,  1.,  3.],\n",
        "     [ 4.,  1., -2.]]\n",
        "\n",
        "X_normalize = normalize(X, norm='l2')\n",
        "\n",
        "print('\\n normalize(): ', X_normalize)\n",
        "\n",
        "normalizer = Normalizer()\n",
        "X_n = normalizer.fit_transform(X)\n",
        "\n",
        "print('\\n Normalizer: ', X_n)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " normalize():  [[0.26559604 0.74550656 0.35075846 0.5006468 ]\n",
            " [0.01569911 0.6541585  0.50910357 0.55914555]\n",
            " [0.30934462 0.88047313 0.27593517 0.23007119]]\n",
            "\n",
            " Normalizer:  [[0.26559604 0.74550656 0.35075846 0.5006468 ]\n",
            " [0.01569911 0.6541585  0.50910357 0.55914555]\n",
            " [0.30934462 0.88047313 0.27593517 0.23007119]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jKVKn3yMV_Ql",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Encode categorical features"
      ]
    },
    {
      "metadata": {
        "id": "yqbHBx64Xqx3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### OrdinalEncoder"
      ]
    },
    {
      "metadata": {
        "id": "21F280RiWC_D",
        "colab_type": "code",
        "outputId": "97ba4f68-0c58-40c5-b854-1e508cec1853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "enc = OrdinalEncoder()\n",
        "\n",
        "X = [['male', 'from US', 'uses Safari'], \n",
        "     ['female', 'from Europe', 'uses Firefox']]\n",
        "enc.fit(X)\n",
        "\n",
        "X_enc = enc.transform(X)\n",
        "print(X_enc)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 1. 1.]\n",
            " [0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "teLBppV1XuwR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### OneHotEncoder"
      ]
    },
    {
      "metadata": {
        "id": "EHnaE3KBXw2T",
        "colab_type": "code",
        "outputId": "1d603acd-aa83-4fda-fcd6-49d0fd454187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "enc = OneHotEncoder()\n",
        "\n",
        "X = [['male', 'from US', 'uses Safari'], \n",
        "     ['female', 'from Europe', 'uses Firefox']]\n",
        "enc.fit(X)\n",
        "\n",
        "X_enc = enc.transform(X).toarray()\n",
        "print(X_enc)\n",
        "\n",
        "print('\\n Categories: \\n', enc.categories_)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. 1. 0. 1.]\n",
            " [1. 0. 1. 0. 1. 0.]]\n",
            "\n",
            " Categories: \n",
            " [array(['female', 'male'], dtype=object), array(['from Europe', 'from US'], dtype=object), array(['uses Firefox', 'uses Safari'], dtype=object)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eF-knCpNZAcJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Discretization\n",
        "Divide continuous features into discrete values."
      ]
    },
    {
      "metadata": {
        "id": "9j88rrmiaXcE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### KBinsDiscretizer"
      ]
    },
    {
      "metadata": {
        "id": "bqGYVe4IZMov",
        "colab_type": "code",
        "outputId": "ae4a187f-92d9-46ea-fd4f-2e118cacc198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "X = np.array([[ -3., 5., 15 ],\n",
        "              [  0., 6., 14 ],\n",
        "              [  6., 3., 11 ]])\n",
        "\n",
        "enc = KBinsDiscretizer(n_bins=[3, 2, 2], encode='ordinal').fit(X)\n",
        "\n",
        "print(enc.transform(X))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [2. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "owb-o9TGbDe1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Binarizer"
      ]
    },
    {
      "metadata": {
        "id": "R12KhgimbGb4",
        "colab_type": "code",
        "outputId": "70485e5d-70c4-4935-a119-bd7354f11285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "X = [[ 1., -2.,  2.],\n",
        "     [ -2.,  1.,  3.],\n",
        "     [ 4.,  1., -2.]]\n",
        "\n",
        "bin = Binarizer().fit(X)\n",
        "\n",
        "print(bin.transform(X))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}